{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d2a458b-dfc1-42e0-bcf6-00e2bdf10137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA_DIR is existant under: C:\\Users\\LukasGrahl\\Documents\\GIT\\memoire1\\data\n"
     ]
    }
   ],
   "source": [
    "%run init_notebookspace.py\n",
    "from settings import DATA_DIR, MODEL_DIR, POST_EST_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39d5c8a0-1a05-493a-ac8c-c336fb6d7340",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import arviz as az\n",
    "from gEconpy.classes.model import gEconModel\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import time\n",
    "import math\n",
    "from scipy.stats import percentileofscore\n",
    "from copy import deepcopy\n",
    "\n",
    "from scipy.stats import gamma, norm, beta, uniform\n",
    "from filterpy.kalman import KalmanFilter\n",
    "from filterpy.common import Saver\n",
    "\n",
    "\n",
    "from src.plotting import plot_dfs\n",
    "from src.process_data import load_data\n",
    "from src.filtering_sampling import set_up_kalman_filter, kalman_filter, sample_from_priors, solve_updated_mod\n",
    "from src.utils import printProgBar, get_arr_pdf_from_dist\n",
    "from src.classes import Spinner\n",
    "\n",
    "from config import plt_config\n",
    "plt.rcParams.update(plt_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9740e1-2261-4f63-88f1-4013724d694d",
   "metadata": {},
   "source": [
    "load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "314c06bf-75e1-49ce-ab90-d445f9e9e890",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occured 'pi_c', file_dict may be incomplete\n",
      "Error occured 'S', file_dict may be incomplete\n",
      "Error occured 'is_test', file_dict may be incomplete\n"
     ]
    }
   ],
   "source": [
    "from config import fred_dict\n",
    "\n",
    "df = load_data('prepro_data.csv', DATA_DIR, fred_dict)\n",
    "\n",
    "# using real potential GDP instead of GDP\n",
    "df = df.drop(['Ix', 'Zx', 'Y', 'pi_s', 'w'], axis=1).rename(columns={'Y_p': 'Y', 'pi_c': 'pi'})\n",
    "\n",
    "# split train and test\n",
    "train = df[df['is_test'] == False].drop('is_test', axis=1).copy()\n",
    "test = df[df['is_test'] == True].drop('is_test', axis=1).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0c112c-36b5-470c-b1b5-b4ef8c9a6200",
   "metadata": {},
   "source": [
    "load & solve model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bad0afd1-1386-46d7-9046-1e78bcd8f725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steady state found! Sum of squared residuals is 0.0\n",
      "Solution found, sum of squared residuals:  3.5962834363340206e-33\n",
      "Norm of deterministic part: 0.000000000\n",
      "Norm of stochastic part:    0.000000000\n",
      "Model solution has 2 eigenvalues greater than one in modulus and 2 forward-looking variables.\n",
      "Blanchard-Kahn condition is satisfied.\n"
     ]
    }
   ],
   "source": [
    "from config import mod4_params, mod4_priors, mod5_params, mod5_priors, mod6_params, mod6_priors\n",
    "mods = {\n",
    "    # 'mod4_rbc_vanilla': {'params': mod4_params,\n",
    "    #                      'priors': mod4_priors,\n",
    "    #                          'is_lin': False},\n",
    "    # 'mod5_nk_vanilla': {'params': mod5_params,\n",
    "    #                     'priors': mod5_priors,\n",
    "    #                     'is_lin': False},    \n",
    "    'mod6_nk_energy_lin2': {'params': mod6_params,\n",
    "                            'is_lin': True,\n",
    "                            'priors': mod6_priors},\n",
    "}\n",
    "\n",
    "# load model\n",
    "for key in mods.keys():\n",
    "    # load\n",
    "    mods[key]['mod'] = gEconModel(os.path.join(MODEL_DIR, f'{key}.gcn'), verbose=False)\n",
    "    \n",
    "    # solve\n",
    "    _, mods[key]['mod'] = solve_updated_mod(mods[key]['mod'], verbose=True, model_is_linear=mods[key]['is_lin'])\n",
    "    assert _ == True, f'{key} model was not solvable'\n",
    "    \n",
    "    # get shocks\n",
    "    mods[key]['shocks'] = [item.base_name for item in mods[key]['mod'].shocks]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876063f7-815b-4b26-ae1c-c0a2d3cc78a2",
   "metadata": {},
   "source": [
    "## drawing from priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4ab7a26-860d-4bc6-b0f1-987ed32f7bb6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[CPI_t, C_t, S_t, Y_t, i_t, pi_t, r_t]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod_name = 'mod6_nk_energy_lin2'\n",
    "\n",
    "mod = mods[mod_name]['mod']\n",
    "mod_params = mod.free_param_dict\n",
    "prior_dist = mods[mod_name]['priors']\n",
    "mod_is_linear = mods[mod_name]['is_lin']\n",
    "\n",
    "mod.variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb2b632b-8c03-4b1d-ba34-8b47a03dbad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Sigma(priors: dict, mod_params: dict, shock_names: list) -> (dict, dict, dict):\n",
    "    params = {k: v for k, v in zip(priors.keys(), [item.std() for item in priors.values()]) if k in mod_params}\n",
    "    shocks = {k: v for k, v in zip(priors.keys(), [item.std() for item in priors.values()]) if k in shock_names}\n",
    "    return params, shocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ff76dc-f573-46eb-a164-808c3a9c445a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1bd1643b-50df-469d-86b4-b3eb15f95452",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.0% \n",
      "\n",
      "loop ran for 18.83803363641103 minutes\n",
      "\n",
      "solver rate 0.6034\n",
      "\n",
      "acceptance rate 0.23201856148491878\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "n_runs = 10_000\n",
    "verbose = False\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# counters\n",
    "counter_solved = 0 # model was sovable\n",
    "counter_kalman = 0 # kalman filter did not fail\n",
    "counter_accp = 0 # draw was accepted\n",
    "\n",
    "# reset params\n",
    "mod.free_param_dict.update(mod_params)\n",
    "\n",
    "# get params, variables and shocks as lists\n",
    "shock_names = [x.base_name for x in mod.shocks]\n",
    "state_variables = [x.base_name for x in mod.variables]\n",
    "model_params = list(mod.free_param_dict.keys())\n",
    "\n",
    "# set kalman filter observed variables\n",
    "observed_vars = [\"Y\", 'C', 'r']\n",
    "_ = [item for item in observed_vars if item not in state_variables]\n",
    "assert len(_) == 0, f\"{_} not in state variables\"\n",
    "\n",
    "# get posterior output list\n",
    "param_posterio_list = {item: [mod.free_param_dict[item]] for item in model_params if item in prior_dist.keys()}\n",
    "shock_posterior_list = {item: [.1] for item in shock_names}\n",
    "loglike_list = [-100]\n",
    "\n",
    "# get simga and scaling factor\n",
    "p, s = get_Sigma(prior_dist, mod_params, shock_names)\n",
    "Σ_params = np.array(list(p.values()))\n",
    "Σ_shocks = np.array(list(s.values()))\n",
    "\n",
    "Σ_params = np.zeros(len(p)) + 1\n",
    "Σ_shocks = np.zeros(len(s)) + 1\n",
    "\n",
    "\n",
    "scaling_factor = .4\n",
    "\n",
    "# get final ouput\n",
    "output_dict = {}\n",
    "\n",
    "for i in range(0, n_runs):\n",
    "    printProgBar(i, n_runs-1, prefix='Progress')\n",
    "    \n",
    "    # set dict to capture results of this run\n",
    "    draw_dict = {\n",
    "        'log_like_list': None,\n",
    "        'log_like_sum': None,\n",
    "        'is_solved': False,\n",
    "        'ratio': None,\n",
    "        'omega': None,\n",
    "        'is_KF_solved': False,\n",
    "        'KF_execption': None,\n",
    "        'is_accepted': False,\n",
    "        'parameters': {\n",
    "            'prior': {item: None for item in model_params if item in prior_dist.keys()},\n",
    "            'prior_pdf_p': {item: None for item in model_params if item in prior_dist.keys()},\n",
    "            'posterior': {item: None for item in model_params if item in prior_dist.keys()}\n",
    "        },\n",
    "        'shocks': {\n",
    "            'prior': {item: None for item in shock_names},\n",
    "            'prior_pdf_s': {item: None for item in shock_names if item in prior_dist.keys()},\n",
    "            'posterior': {item: None for item in shock_names}\n",
    "        }\n",
    "    }\n",
    "    # current posterior\n",
    "    old_posterior_p = {item: vals[-1] for item, vals in param_posterio_list.items()}\n",
    "    old_posterior_s = {item: vals[-1] for item, vals in shock_posterior_list.items()}\n",
    "    old_loglike = loglike_list[-1]\n",
    "    \n",
    "    draw_dict['parameters']['posterior'] = old_posterior_p\n",
    "    draw_dict['shocks']['posterior'] = old_posterior_s\n",
    "    \n",
    "    \n",
    "    # sample from priors\n",
    "    # prior, shocks = sample_from_priors(prior_dist, mod_params, shock_names)\n",
    "    prior = np.array(list(old_posterior_p.values()) + multivariate_normal(list([0] * len(old_posterior_p)), scaling_factor * Σ_params).rvs())\n",
    "    shocks = np.array(list(old_posterior_s.values()) + multivariate_normal(list([0] * len(old_posterior_s)), scaling_factor * Σ_shocks).rvs())\n",
    "    prior, shocks = dict(zip(old_posterior_p.keys(), prior)), dict(zip(old_posterior_s.keys(), shocks))\n",
    "    \n",
    "    draw_dict['parameters']['prior'].update(prior)\n",
    "    draw_dict['shocks']['prior'].update(shocks)\n",
    "    \n",
    "    mod.free_param_dict.update(prior)\n",
    "    mod.shock_priors.update(shocks)\n",
    "\n",
    "    # sovle mdoel\n",
    "    is_solved, mod = solve_updated_mod(mod, verbose=verbose, model_is_linear=mod_is_linear)\n",
    "    if not is_solved:\n",
    "        output_dict[i] = draw_dict\n",
    "        continue\n",
    "    else:\n",
    "        draw_dict['is_solved'] = True\n",
    "        counter_solved += 1\n",
    "    \n",
    "    # get Kalman filter initial condition\n",
    "    T, R = mod.T.values, mod.R.values\n",
    "    H, Z, T, R, QN, zs = set_up_kalman_filter(R=R, T=T, observed_data=train[observed_vars].values, observed_vars=observed_vars, \n",
    "                                              shock_names=shock_names, shocks_drawn_prior=shocks, state_variables=state_variables)\n",
    "       \n",
    "    # set up Kalman filter\n",
    "    kfilter = KalmanFilter(len(state_variables), len(observed_vars))\n",
    "    kfilter.F = T\n",
    "    kfilter.Q = QN\n",
    "    kfilter.H = Z\n",
    "    kfilter.R = H\n",
    "\n",
    "    # run Kalman filter\n",
    "    try:\n",
    "        saver = Saver(kfilter)\n",
    "        mu, cov, _, _ = kfilter.batch_filter(zs, saver=saver)\n",
    "        ll = saver.log_likelihood\n",
    "        \n",
    "         # catch -math.inf values in log_likelihood\n",
    "        if len([val for val in ll if val == -math.inf]) >0:\n",
    "            output_dict[i] = draw_dict\n",
    "            continue\n",
    "        \n",
    "        # otherwise keep going\n",
    "        new_loglike = np.sum(ll)\n",
    "        loglike_list.append(new_loglike)\n",
    "    \n",
    "        draw_dict['log_like_sum'] = new_loglike\n",
    "        draw_dict['log_like_list'] = ll\n",
    "        \n",
    "        draw_dict['is_KF_solved'] = True\n",
    "        counter_kalman += 1\n",
    "        \n",
    "    except Exception as e:\n",
    "        draw_dict['KF_execption'] = e\n",
    "        output_dict[i] = draw_dict\n",
    "        continue\n",
    "\n",
    "    #### MH #####  \n",
    "    # MH ratio\n",
    "    prior_pdf_p = get_arr_pdf_from_dist(prior, prior_dist)\n",
    "    prior_pdf_s = get_arr_pdf_from_dist(shocks, prior_dist)\n",
    "    \n",
    "    draw_dict['parameters']['prior_pdf_p'] = dict(zip(prior.keys(), prior_pdf_p))\n",
    "    draw_dict['shocks']['prior_pdf_s'] = dict(zip(prior.keys(), prior_pdf_s))\n",
    "    \n",
    "    prior_pdf = np.append(prior_pdf_p, prior_pdf_s)\n",
    "    mask_old_post = np.append(get_arr_pdf_from_dist(old_posterior_p, prior_dist), get_arr_pdf_from_dist(old_posterior_s, prior_dist))\n",
    "    \n",
    "    ratio = (new_loglike * prior_pdf / old_loglike * mask_old_post).mean()\n",
    "    \n",
    "    ω = min([ratio, 1])\n",
    "    draw_dict['ratio'] = ratio\n",
    "    draw_dict['omega'] = ω\n",
    "    random = np.random.uniform(0, 1)\n",
    "        \n",
    "    # merge draws prior into posterior \n",
    "    if random <= ω:\n",
    "        counter_accp += 1.\n",
    "        draw_dict['is_accepted'] = True\n",
    "        \n",
    "        # update param posterior\n",
    "        for key in prior.keys():\n",
    "            param_posterio_list[key].append(prior[key])\n",
    "        \n",
    "        # update shock posterior\n",
    "        for key in shock_posterior_list:\n",
    "            shock_posterior_list[key].append(shocks[key])\n",
    "                \n",
    "    else:\n",
    "        # leave posterior unaltered and restart\n",
    "        is_accepted = False\n",
    "        \n",
    "    # save output    \n",
    "    output_dict[i] = draw_dict\n",
    "        \n",
    "\n",
    "# print stats\n",
    "print('\\nloop ran for', (time.time() - start) / 60, 'minutes')\n",
    "print('\\nsolver rate', counter_solved/n_runs)\n",
    "print('\\nacceptance rate', counter_accp/counter_solved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b735399b-33e5-4301-b6df-d04fbb24ff56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed331715-6cef-4650-8762-ced15176aaf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = list(param_posterio_list.keys())\n",
    "\n",
    "xarr = xr.Dataset(\n",
    "    {\n",
    "        # draw & param dimension\n",
    "        'posterior_param': (['draw', 'parameter'],[np.array(list(output_dict[i]['parameters']['posterior'].values())) for i in output_dict.keys()]),\n",
    "        'posterior_shock': (['draw', 'shock'],[np.array(list(output_dict[i]['shocks']['posterior'].values())) for i in output_dict.keys()]),\n",
    "        'prior_param': (['draw', 'parameter'], [np.array(list(output_dict[i]['parameters']['prior'].values())) for i in output_dict.keys()]),\n",
    "        'prior_shock': (['draw', 'shock'], [np.array(list(output_dict[i]['shocks']['prior'].values())) for i in output_dict.keys()]),\n",
    "        'prior_pdf_params': (['draw', 'parameter'], [np.array(list(output_dict[i]['parameters']['prior_pdf_p'].values())) for i in output_dict.keys()]),\n",
    "        'prior_pdf_shocks': (['draw', 'shock'], [np.array(list(output_dict[i]['shocks']['prior_pdf_s'].values())) for i in output_dict.keys()]),\n",
    "        \n",
    "        # draw dimension\n",
    "        'is_solved': (['draw'], [output_dict[i]['is_solved'] for i in output_dict.keys()]),\n",
    "        'is_accepted': (['draw'], [output_dict[i]['is_accepted'] for i in output_dict.keys()]),\n",
    "        'log_likelihood': (['draw'], [output_dict[i]['log_like_sum'] for i in output_dict.keys()]),\n",
    "        'mh_ratio': (['draw'], [output_dict[i]['ratio'] for i in output_dict.keys()]),\n",
    "        \n",
    "        # uni dimensional\n",
    "        'n_runs_acc': (['uni_dim'], [counter_accp]),\n",
    "        'n_runs': (['uni_dim'], [n_runs]), # number of solved models  \n",
    "    },\n",
    "    coords={\n",
    "        'draw': (['draw'], list(range(0, int(n_runs)))),\n",
    "        'parameter': (['parameter'], params),\n",
    "        'shock': (['shock'], shock_names),\n",
    "        'uni_dim': (['uni_dim'], [0])\n",
    "    }\n",
    ")\n",
    "\n",
    "# only accepted runs\n",
    "xarr_acc = xarr.where(xarr.draw >= int(xarr.n_runs / 2)).dropna('draw').copy()\n",
    "# xarr_acc.where(xarr.is_accepted).dropna('draw')\n",
    "\n",
    "# get quantiles of parameters\n",
    "arr_nan = deepcopy(xarr_acc.posterior_param.values)\n",
    "arr_nan = np.array(arr_nan, dtype=float)\n",
    "\n",
    "for i in range(0, arr_nan.shape[1]):\n",
    "    arr_no_nan = arr_nan[~np.isnan(arr_nan[:, i]), i]\n",
    "    arr_nan[~np.isnan(arr_nan[:, i]), i] = [percentileofscore(arr_no_nan, x, 'rank') for x in arr_no_nan]\n",
    "xarr_acc = xarr_acc.assign({'posterior_percentiles': (['draw', 'parameter'], arr_nan)})\n",
    "\n",
    "\n",
    "quantile_ind = []\n",
    "for i in [25, 50, 75]:\n",
    "    arr = np.abs(xarr_acc.posterior_percentiles.mean(axis=1) - i)\n",
    "    quantile_ind.append(np.where(arr==np.min(arr))[0][0])\n",
    "    \n",
    "xarr_acc = xarr_acc.assign({\n",
    "    'posterior_q1': (['parameter'], xarr.sel(draw=quantile_ind[0]).posterior_param.values),\n",
    "    'posterior_q2': (['parameter'], xarr.sel(draw=quantile_ind[1]).posterior_param.values),\n",
    "    'posterior_q3': (['parameter'], xarr.sel(draw=quantile_ind[2]).posterior_param.values)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16071792-fe84-4227-957d-546b46e4e8b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e1a98c6-b6ed-4312-9fcd-ec31c479a750",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LukasGrahl\\Documents\\GIT\\memoire1\\data\\posterior_est_out\\mod6_nk_energy_lin2_20230510_1823.nc\n"
     ]
    }
   ],
   "source": [
    "# save output\n",
    "from datetime import datetime\n",
    "\n",
    "a = ''.join(str(datetime.now().date()).split('-'))\n",
    "b = ''.join((str(datetime.now().time()).split(':'))[:-1])\n",
    "timestamp = '_'.join([a, b])\n",
    "\n",
    "file_path = os.path.join(POST_EST_DIR, f'{mod_name}_{timestamp}.nc')\n",
    "file_path_acc = os.path.join(POST_EST_DIR, f'{mod_name}_accepted_{timestamp}.nc')\n",
    "print(file_path)\n",
    "if not os.path.exists(file_path):\n",
    "    xarr.to_netcdf(file_path)\n",
    "    \n",
    "if not os.path.exists(file_path_acc):\n",
    "    xarr_acc.to_netcdf(file_path_acc)\n",
    "    \n",
    "else:\n",
    "    print('File existst already')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90992be7-5d80-4f5c-9695-403e0aaa37df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
