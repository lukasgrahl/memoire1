{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d2a458b-dfc1-42e0-bcf6-00e2bdf10137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA_DIR is existant under: C:\\Users\\LukasGrahl\\Documents\\GIT\\memoire1\\data\n"
     ]
    }
   ],
   "source": [
    "%run init_notebookspace.py\n",
    "from settings import DATA_DIR, MODEL_DIR, POST_EST_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39d5c8a0-1a05-493a-ac8c-c336fb6d7340",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import arviz as az\n",
    "from gEconpy.classes.model import gEconModel\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import time\n",
    "import math\n",
    "from scipy.stats import percentileofscore\n",
    "from copy import deepcopy\n",
    "\n",
    "from scipy.stats import gamma, norm, beta, uniform\n",
    "from filterpy.kalman import KalmanFilter\n",
    "from filterpy.common import Saver\n",
    "\n",
    "\n",
    "from src.plotting import plot_dfs\n",
    "from src.process_data import load_data\n",
    "from src.filtering_sampling import set_up_kalman_filter, kalman_filter, sample_from_priors, solve_updated_mod, get_Sigma\n",
    "from src.utils import printProgBar, get_arr_pdf_from_dist\n",
    "from src.classes import Spinner\n",
    "\n",
    "from config import plt_config\n",
    "plt.rcParams.update(plt_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9740e1-2261-4f63-88f1-4013724d694d",
   "metadata": {},
   "source": [
    "load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "314c06bf-75e1-49ce-ab90-d445f9e9e890",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occured 's', file_dict may be incomplete\n",
      "Error occured 'is_test', file_dict may be incomplete\n"
     ]
    }
   ],
   "source": [
    "from config import fred_dict\n",
    "\n",
    "df = load_data('prepro_data.csv', DATA_DIR, fred_dict)\n",
    "\n",
    "# using real potential GDP instead of GDP\n",
    "df = df.drop(['Ix', 'Zx', 'y', 'pi_s', 'w'], axis=1).rename(columns={'y_p': 'y', 'pi_c': 'pi'})\n",
    "df = df.iloc[90:]\n",
    "\n",
    "# split train and test\n",
    "train = df[df['is_test'] == False].drop('is_test', axis=1).copy()\n",
    "test = df[df['is_test'] == True].drop('is_test', axis=1).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0c112c-36b5-470c-b1b5-b4ef8c9a6200",
   "metadata": {},
   "source": [
    "load & solve model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bad0afd1-1386-46d7-9046-1e78bcd8f725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steady state found! Sum of squared residuals is 6.1286653075070395e-27\n",
      "Solution found, sum of squared residuals:  2.563134175042647e-31\n",
      "Norm of deterministic part: 0.000000000\n",
      "Norm of stochastic part:    0.000000000\n",
      "Model solution has 2 eigenvalues greater than one in modulus and 2 forward-looking variables.\n",
      "Blanchard-Kahn condition is satisfied.\n"
     ]
    }
   ],
   "source": [
    "from config import mod4_params, mod4_priors, mod5_params, mod5_priors, mod6_params, mod6_priors\n",
    "mods = {\n",
    "    'mod4_rbc_vanilla': {'params': mod4_params,\n",
    "                         'priors': mod4_priors,\n",
    "                         'is_lin': False,\n",
    "                         'name': 'RBC'},\n",
    "    'mod5_nk_vanilla_lin2': {'params': mod5_params,\n",
    "                            'priors': mod5_priors,\n",
    "                            'is_lin': True,\n",
    "                             'name': 'NK'},\n",
    "    'mod6_nk_energy_lin2': {'params': mod6_params,\n",
    "                           'is_lin': True,\n",
    "                           'priors': mod6_priors,\n",
    "                           'name': 'NK Petrol'}\n",
    "}\n",
    "\n",
    "\n",
    "mod_name = 'mod5_nk_vanilla_lin2'\n",
    "mod_is_linear = mods[mod_name]['is_lin']\n",
    "\n",
    "mod = gEconModel(os.path.join(MODEL_DIR, f'{mod_name}.gcn'), verbose=False)\n",
    "_, mod = solve_updated_mod(mod, verbose=True, model_is_linear=mod_is_linear)\n",
    "\n",
    "mod_params = mod.free_param_dict\n",
    "prior_dist = mods[mod_name]['priors']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876063f7-815b-4b26-ae1c-c0a2d3cc78a2",
   "metadata": {},
   "source": [
    "## drawing from priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1bd1643b-50df-469d-86b4-b3eb15f95452",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.0% \n",
      "\n",
      "loop ran for 4.84713431596756 minutes\n",
      "\n",
      "solver rate 0.6332\n",
      "\n",
      "acceptance rate 0.7792166771951989\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "# number of draws for the sampler\n",
    "n_runs = 20_000\n",
    "\n",
    "verbose = False\n",
    "start = time.time()\n",
    "\n",
    "# counters\n",
    "counter_solved = 0 # model was sovable\n",
    "counter_kalman = 0 # kalman filter did not fail\n",
    "counter_accp = 0 # draw was accepted into posterior\n",
    "\n",
    "# reset params in the model\n",
    "mod.free_param_dict.update(mod_params)\n",
    "\n",
    "# get params, variables and shocks as lists\n",
    "shock_names = [x.base_name for x in mod.shocks]\n",
    "state_variables = [x.base_name for x in mod.variables]\n",
    "model_params = list(mod.free_param_dict.keys())\n",
    "\n",
    "# set kalman filter observed variables\n",
    "observed_vars = ['y', 'n', 'r']\n",
    "_ = [item for item in observed_vars if item not in state_variables]\n",
    "assert len(_) == 0, f\"{_} not in state variables\"\n",
    "\n",
    "# get posterior output list\n",
    "param_posterio_list = {item: [mod.free_param_dict[item]] for item in model_params if item in prior_dist.keys()}\n",
    "shock_posterior_list = {item: [.1] for item in shock_names}\n",
    "loglike_list = [-100]\n",
    "\n",
    "# get simga and scaling factor for the random walk law of motion\n",
    "p, s = get_Sigma(prior_dist, mod_params, shock_names)\n",
    "G_params = np.array(list(p.values())) \n",
    "G_shocks = np.array(list(s.values()))\n",
    "\n",
    "# sacling factor for random walk law of motion\n",
    "scaling_factor = .25\n",
    "\n",
    "# get final ouput\n",
    "output_dict = {}\n",
    "\n",
    "for i in range(0, n_runs):\n",
    "    printProgBar(i, n_runs-1, prefix='Progress')\n",
    "    if (i== int(n_runs/3)) & (counter_solved>0):\n",
    "        if (counter_accp/counter_solved <= .05):\n",
    "            print(f'Current acceptance rate below 5%')\n",
    "    \n",
    "    \n",
    "    # set dict to capture results of this run\n",
    "    draw_dict = {\n",
    "        'log_like_list': None,\n",
    "        'log_like_sum': None,\n",
    "        'is_solved': False,\n",
    "        'ratio': None,\n",
    "        'omega': None,\n",
    "        'is_KF_solved': False,\n",
    "        'KF_execption': None,\n",
    "        'is_accepted': False,\n",
    "        'parameters': {\n",
    "            'prior': {item: None for item in model_params if item in prior_dist.keys()},\n",
    "            'prior_pdf_p': {item: None for item in model_params if item in prior_dist.keys()},\n",
    "            'posterior': {item: None for item in model_params if item in prior_dist.keys()}\n",
    "        },\n",
    "        'shocks': {\n",
    "            'prior': {item: None for item in shock_names},\n",
    "            'prior_pdf_s': {item: None for item in shock_names if item in prior_dist.keys()},\n",
    "            'posterior': {item: None for item in shock_names}\n",
    "        }\n",
    "    }\n",
    "    # current posterior\n",
    "    old_posterior_p = {item: vals[-1] for item, vals in param_posterio_list.items()}\n",
    "    old_posterior_s = {item: vals[-1] for item, vals in shock_posterior_list.items()}\n",
    "    old_loglike = loglike_list[-1]\n",
    "    \n",
    "    # save posterior information to output dict\n",
    "    draw_dict['parameters']['posterior'] = old_posterior_p\n",
    "    draw_dict['shocks']['posterior'] = old_posterior_s\n",
    "    \n",
    "    \n",
    "    # sample from priors according to random walk law of motion\n",
    "    # a multivariate normal distribution wit G as standard deviation\n",
    "    \n",
    "    # prior for parameters\n",
    "    prior = np.array(list(old_posterior_p.values()) + multivariate_normal(list([0] * len(old_posterior_p)), scaling_factor * G_params).rvs())\n",
    "    \n",
    "    # prior for shocks\n",
    "    shocks = np.array(list(old_posterior_s.values()) + multivariate_normal(list([0] * len(old_posterior_s)), scaling_factor * G_shocks).rvs())\n",
    "    \n",
    "    # put priors into dictionary for further process\n",
    "    prior, shocks = dict(zip(old_posterior_p.keys(), prior)), dict(zip(old_posterior_s.keys(), shocks))\n",
    "\n",
    "    draw_dict['parameters']['prior'].update(prior)\n",
    "    draw_dict['shocks']['prior'].update(shocks)\n",
    "    \n",
    "    # update model with new parameters and shocks\n",
    "    mod.free_param_dict.update(prior)\n",
    "    mod.shock_priors.update(shocks)\n",
    "\n",
    "    # solve model for new steady state and transition matrix T\n",
    "    # if model is not solved discard and proceed to nex iteration\n",
    "    is_solved, mod = solve_updated_mod(mod, verbose=verbose, model_is_linear=mod_is_linear)\n",
    "    if not is_solved:\n",
    "        output_dict[i] = draw_dict\n",
    "        continue\n",
    "    else:\n",
    "        draw_dict['is_solved'] = True\n",
    "        counter_solved += 1\n",
    "    \n",
    "    # get Kalman filter matrices\n",
    "    T, R = mod.T.values, mod.R.values\n",
    "    H, Z, T, R, QN, zs = set_up_kalman_filter(R=R, T=T, observed_data=train[observed_vars].values, observed_vars=observed_vars, \n",
    "                                              shock_names=shock_names, shocks_drawn_prior=shocks, state_variables=state_variables)\n",
    "       \n",
    "    # set up Kalman filter\n",
    "    kfilter = KalmanFilter(len(state_variables), len(observed_vars))\n",
    "    kfilter.F = T\n",
    "    kfilter.Q = QN\n",
    "    kfilter.H = Z\n",
    "    kfilter.R = H\n",
    "\n",
    "    # run Kalman filter\n",
    "    try:\n",
    "        saver = Saver(kfilter)\n",
    "        mu, cov, _, _ = kfilter.batch_filter(zs, saver=saver)\n",
    "        ll = saver.log_likelihood\n",
    "        \n",
    "         # catch -math.inf values in log_likelihood, meaning that the filter did not converge\n",
    "        if len([val for val in ll if val == -math.inf]) >0:\n",
    "            output_dict[i] = draw_dict\n",
    "            continue\n",
    "        \n",
    "        # sum-up individual log-likelihoods in order to obtain the ll for this run\n",
    "        new_loglike = np.sum(ll)\n",
    "        loglike_list.append(new_loglike)\n",
    "    \n",
    "        # save information in dict and update counters\n",
    "        draw_dict['log_like_sum'] = new_loglike\n",
    "        draw_dict['log_like_list'] = ll\n",
    "        draw_dict['is_KF_solved'] = True\n",
    "        counter_kalman += 1\n",
    "    \n",
    "    # catch possible errors in KFilter for debugging\n",
    "    except Exception as e:\n",
    "        draw_dict['KF_execption'] = e\n",
    "        output_dict[i] = draw_dict\n",
    "        continue\n",
    "    \n",
    "    # Metropolis Hastings MCMC sampler\n",
    "    \n",
    "    # get prior likelihood\n",
    "    prior_pdf_p = get_arr_pdf_from_dist(prior, prior_dist)\n",
    "    prior_pdf_s = get_arr_pdf_from_dist(shocks, prior_dist)\n",
    "    prior_pdf = np.append(prior_pdf_p, prior_pdf_s)\n",
    "    \n",
    "    # save prior likelihood\n",
    "    draw_dict['parameters']['prior_pdf_p'] = dict(zip(prior.keys(), prior_pdf_p))\n",
    "    draw_dict['shocks']['prior_pdf_s'] = dict(zip(prior.keys(), prior_pdf_s))\n",
    "    \n",
    "    # get current posterior likelihood    \n",
    "    mask_old_post = np.append(get_arr_pdf_from_dist(old_posterior_p, prior_dist), get_arr_pdf_from_dist(old_posterior_s, prior_dist))\n",
    "    \n",
    "    # compare current prior likelihood with the likelihood of the most recent draw accepted into the posterior\n",
    "    ratio = (new_loglike * prior_pdf / old_loglike * mask_old_post).mean()\n",
    "    ω = min([ratio, 1])\n",
    "    # save ratios\n",
    "    draw_dict['ratio'] = ratio\n",
    "    draw_dict['omega'] = ω\n",
    "              \n",
    "    # MH sampler random acceptance, based on uniform distribution U(0,1)\n",
    "    rand = np.random.uniform(0, 1)\n",
    "    if rand <= ω:\n",
    "        counter_accp += 1.\n",
    "        draw_dict['is_accepted'] = True\n",
    "        \n",
    "        # update param posterior\n",
    "        for key in prior.keys():\n",
    "            param_posterio_list[key].append(prior[key])\n",
    "        \n",
    "        # update shock posterior\n",
    "        for key in shock_posterior_list:\n",
    "            shock_posterior_list[key].append(shocks[key])\n",
    "                \n",
    "    else:\n",
    "        # leave posterior unaltered and restart\n",
    "        is_accepted = False\n",
    "        \n",
    "    # save output    \n",
    "    output_dict[i] = draw_dict\n",
    "\n",
    "# print stats\n",
    "print('\\nloop ran for', (time.time() - start) / 60, 'minutes')\n",
    "print('\\nsolver rate', counter_solved/n_runs)\n",
    "print('\\nacceptance rate', counter_accp/counter_solved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ed331715-6cef-4650-8762-ced15176aaf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = list(param_posterio_list.keys())\n",
    "\n",
    "xarr = xr.Dataset(\n",
    "    {\n",
    "        # draw & param dimension\n",
    "        'posterior_param': (['draw', 'parameter'],[np.array(list(output_dict[i]['parameters']['posterior'].values())) for i in output_dict.keys()]),\n",
    "        'posterior_shock': (['draw', 'shock'],[np.array(list(output_dict[i]['shocks']['posterior'].values())) for i in output_dict.keys()]),\n",
    "        'prior_param': (['draw', 'parameter'], [np.array(list(output_dict[i]['parameters']['prior'].values())) for i in output_dict.keys()]),\n",
    "        'prior_shock': (['draw', 'shock'], [np.array(list(output_dict[i]['shocks']['prior'].values())) for i in output_dict.keys()]),\n",
    "        'prior_pdf_params': (['draw', 'parameter'], [np.array(list(output_dict[i]['parameters']['prior_pdf_p'].values())) for i in output_dict.keys()]),\n",
    "        'prior_pdf_shocks': (['draw', 'shock'], [np.array(list(output_dict[i]['shocks']['prior_pdf_s'].values())) for i in output_dict.keys()]),\n",
    "        \n",
    "        # draw dimension\n",
    "        'is_solved': (['draw'], [output_dict[i]['is_solved'] for i in output_dict.keys()]),\n",
    "        'is_accepted': (['draw'], [output_dict[i]['is_accepted'] for i in output_dict.keys()]),\n",
    "        'log_likelihood': (['draw'], [output_dict[i]['log_like_sum'] for i in output_dict.keys()]),\n",
    "        'mh_ratio': (['draw'], [output_dict[i]['ratio'] for i in output_dict.keys()]),\n",
    "        \n",
    "        # uni dimensional\n",
    "        'n_runs_acc': (['uni_dim'], [counter_accp]),\n",
    "        'n_runs': (['uni_dim'], [n_runs]), # number of solved models \n",
    "        # 'kalman_obs_var': (['uni_dim'], (observed_vars)),\n",
    "    },\n",
    "    coords={\n",
    "        'draw': (['draw'], list(range(0, int(n_runs)))),\n",
    "        'parameter': (['parameter'], params),\n",
    "        'shock': (['shock'], shock_names),\n",
    "        'uni_dim': (['uni_dim'], [0])\n",
    "    }\n",
    ")\n",
    "\n",
    "# only accepted runs\n",
    "xarr_acc = xarr.where(xarr.draw >= int(xarr.n_runs / 2)).dropna('draw').copy()\n",
    "# xarr_acc.where(xarr.is_accepted).dropna('draw')\n",
    "\n",
    "# get quantiles of parameters\n",
    "arr_nan = deepcopy(xarr_acc.posterior_param.values)\n",
    "arr_nan = np.array(arr_nan, dtype=float)\n",
    "\n",
    "for i in range(0, arr_nan.shape[1]):\n",
    "    arr_no_nan = arr_nan[~np.isnan(arr_nan[:, i]), i]\n",
    "    arr_nan[~np.isnan(arr_nan[:, i]), i] = [percentileofscore(arr_no_nan, x, 'rank') for x in arr_no_nan]\n",
    "xarr_acc = xarr_acc.assign({'posterior_percentiles': (['draw', 'parameter'], arr_nan)})\n",
    "\n",
    "\n",
    "quantile_ind = []\n",
    "for i in [25, 50, 75]:\n",
    "    arr = np.abs(xarr_acc.posterior_percentiles.mean(axis=1) - i)\n",
    "    quantile_ind.append(np.where(arr==np.min(arr))[0][0])\n",
    "    \n",
    "xarr_acc = xarr_acc.assign({\n",
    "    'posterior_q1': (['parameter'], xarr.sel(draw=quantile_ind[0]).posterior_param.values),\n",
    "    'posterior_q2': (['parameter'], xarr.sel(draw=quantile_ind[1]).posterior_param.values),\n",
    "    'posterior_q3': (['parameter'], xarr.sel(draw=quantile_ind[2]).posterior_param.values)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "92108484-24a1-4d0a-95a7-338de34f33ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['y', 'n', 'r']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observed_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1e1a98c6-b6ed-4312-9fcd-ec31c479a750",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LukasGrahl\\Documents\\GIT\\memoire1\\data\\posterior_est_out\\mod5_nk_vanilla_lin2_20230523_1405.nc\n"
     ]
    }
   ],
   "source": [
    "# save output\n",
    "from datetime import datetime\n",
    "\n",
    "a = ''.join(str(datetime.now().date()).split('-'))\n",
    "b = ''.join((str(datetime.now().time()).split(':'))[:-1])\n",
    "timestamp = '_'.join([a, b])\n",
    "\n",
    "file_path = os.path.join(POST_EST_DIR, f'{mod_name}_{timestamp}.nc')\n",
    "file_path_acc = os.path.join(POST_EST_DIR, f'{mod_name}_accepted_{timestamp}.nc')\n",
    "print(file_path)\n",
    "if not os.path.exists(file_path):\n",
    "    xarr.to_netcdf(file_path)\n",
    "    \n",
    "if not os.path.exists(file_path_acc):\n",
    "    xarr_acc.to_netcdf(file_path_acc)\n",
    "    \n",
    "else:\n",
    "    print('File existst already')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90992be7-5d80-4f5c-9695-403e0aaa37df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
