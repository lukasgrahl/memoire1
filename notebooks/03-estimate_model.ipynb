{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d2a458b-dfc1-42e0-bcf6-00e2bdf10137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA_DIR is existant under: C:\\Users\\LukasGrahl\\Documents\\GIT\\memoire1\\data\n"
     ]
    }
   ],
   "source": [
    "%run init_notebookspace.py\n",
    "from settings import DATA_DIR, MODEL_DIR, POST_EST_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39d5c8a0-1a05-493a-ac8c-c336fb6d7340",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import arviz as az\n",
    "from gEconpy.classes.model import gEconModel\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import time\n",
    "import math\n",
    "from scipy.stats import percentileofscore\n",
    "from copy import deepcopy\n",
    "\n",
    "from scipy.stats import gamma, norm, beta, uniform\n",
    "from filterpy.kalman import KalmanFilter\n",
    "from filterpy.common import Saver\n",
    "\n",
    "\n",
    "from src.plotting import plot_dfs\n",
    "from src.process_data import load_data\n",
    "from src.filtering_sampling import set_up_kalman_filter, kalman_filter, sample_from_priors, solve_updated_mod, get_arr_pdf_from_dist\n",
    "from src.utils import printProgBar\n",
    "from src.classes import Spinner\n",
    "\n",
    "from config import plt_config\n",
    "plt.rcParams.update(plt_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9740e1-2261-4f63-88f1-4013724d694d",
   "metadata": {},
   "source": [
    "load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "314c06bf-75e1-49ce-ab90-d445f9e9e890",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occured 'S', file_dict may be incomplete\n",
      "Error occured 'is_test', file_dict may be incomplete\n"
     ]
    }
   ],
   "source": [
    "from config import fred_dict\n",
    "\n",
    "df = load_data('prepro_data.csv', DATA_DIR, fred_dict)\n",
    "\n",
    "# using real potential GDP instead of GDP\n",
    "df = df.drop(['Ix', 'Zx', 'Y', 'pi_s', 'w'], axis=1).rename(columns={'Y_p': 'Y', 'pi_c': 'pi'})\n",
    "\n",
    "# split train and test\n",
    "train = df[df['is_test'] == False].drop('is_test', axis=1).copy()\n",
    "test = df[df['is_test'] == True].drop('is_test', axis=1).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0c112c-36b5-470c-b1b5-b4ef8c9a6200",
   "metadata": {},
   "source": [
    "load & solve model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bad0afd1-1386-46d7-9046-1e78bcd8f725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steady state found! Sum of squared residuals is 6.695803486498152e-23\n",
      "Solution found, sum of squared residuals:  9.039442757935503e-31\n",
      "Norm of deterministic part: 0.000000000\n",
      "Norm of stochastic part:    0.000000000\n",
      "Model solution has 2 eigenvalues greater than one in modulus and 2 forward-looking variables.\n",
      "Blanchard-Kahn condition is satisfied.\n",
      "Steady state found! Sum of squared residuals is 9.760551087350258e-22\n",
      "Solution found, sum of squared residuals:  3.0464227584645074e-28\n",
      "Norm of deterministic part: 0.000000000\n",
      "Norm of stochastic part:    0.000000000\n",
      "Model solution has 6 eigenvalues greater than one in modulus and 4 forward-looking variables.\n",
      "Blanchard-Kahn condition is satisfied.\n",
      "Steady state found! Sum of squared residuals is 0.0\n",
      "Solution found, sum of squared residuals:  3.5962834363340206e-33\n",
      "Norm of deterministic part: 0.000000000\n",
      "Norm of stochastic part:    0.000000000\n",
      "Model solution has 2 eigenvalues greater than one in modulus and 2 forward-looking variables.\n",
      "Blanchard-Kahn condition is satisfied.\n"
     ]
    }
   ],
   "source": [
    "from config import mod4_params, mod4_priors, mod5_params, mod5_priors, mod6_params, mod6_priors\n",
    "mods = {\n",
    "    'mod4_rbc_vanilla': {'params': mod4_params,\n",
    "                         'priors': mod4_priors,\n",
    "                             'is_lin': False},\n",
    "    'mod5_nk_vanilla': {'params': mod5_params,\n",
    "                        'priors': mod5_priors,\n",
    "                        'is_lin': False},    \n",
    "    'mod6_nk_energy_lin2': {'params': mod6_params,\n",
    "                            'is_lin': True,\n",
    "                            'priors': mod6_priors},\n",
    "}\n",
    "\n",
    "# load model\n",
    "for key in mods.keys():\n",
    "    # load\n",
    "    mods[key]['mod'] = gEconModel(os.path.join(MODEL_DIR, f'{key}.gcn'), verbose=False)\n",
    "    \n",
    "    # solve\n",
    "    _, mods[key]['mod'] = solve_updated_mod(mods[key]['mod'], verbose=True, model_is_linear=mods[key]['is_lin'])\n",
    "    assert _ == True, f'{key} model was not solvable'\n",
    "    \n",
    "    # get shocks\n",
    "    mods[key]['shocks'] = [item.base_name for item in mods[key]['mod'].shocks]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0a9c14-6fbb-488d-923b-ee48011e3241",
   "metadata": {},
   "source": [
    "## Kalman Filter Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876063f7-815b-4b26-ae1c-c0a2d3cc78a2",
   "metadata": {},
   "source": [
    "## drawing from priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4ab7a26-860d-4bc6-b0f1-987ed32f7bb6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[A_t, C_t, I_t, K_t, L_t, Y_t, lambda_t, r_t, w_t]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod_name = 'mod4_rbc_vanilla'\n",
    "mod = mods[mod_name]['mod']\n",
    "mod_params = mod.free_param_dict\n",
    "prior_dist = mods[mod_name]['priors']\n",
    "mod_is_linear = mods[mod_name]['is_lin']\n",
    "\n",
    "mod.variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1bd1643b-50df-469d-86b4-b3eb15f95452",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress |████████████████████████████████████████████████████████████████████████████████████████████████████| 100.0% \n",
      "\n",
      "loop ran for 125.43099851608277 minutes\n",
      "\n",
      "solver rate 0.6796\n",
      "\n",
      "acceptance rate 0.8209240729841083\n"
     ]
    }
   ],
   "source": [
    "n_runs = 10_000\n",
    "verbose = False\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# counters\n",
    "counter_solved = 0 # model was sovable\n",
    "counter_kalman = 0 # kalman filter did not fail\n",
    "counter_accp = 0 # draw was accepted\n",
    "\n",
    "# reset params\n",
    "mod.free_param_dict.update(mod_params)\n",
    "\n",
    "# get params, variables and shocks as lists\n",
    "shock_names = [x.base_name for x in mod.shocks]\n",
    "state_variables = [x.base_name for x in mod.variables]\n",
    "model_params = list(mod.free_param_dict.keys())\n",
    "\n",
    "# set kalman filter observed variables\n",
    "observed_vars = [\"Y\", 'C', 'r']\n",
    "_ = [item for item in observed_vars if item not in state_variables]\n",
    "assert len(_) == 0, f\"{_} not in state variables\"\n",
    "\n",
    "# get posterior output list\n",
    "param_posterio_list = {item: [mod.free_param_dict[item]] for item in model_params if item in prior_dist.keys()}\n",
    "shock_posterior_list = {item: [.1] for item in shock_names}\n",
    "loglike_list = [-100]\n",
    "\n",
    "# get final ouput\n",
    "output_dict = {}\n",
    "\n",
    "for i in range(0, n_runs):\n",
    "    printProgBar(i, n_runs-1, prefix='Progress')\n",
    "    \n",
    "    # set dict to capture results of this run\n",
    "    draw_dict = {\n",
    "        'log_like_list': None,\n",
    "        'log_like_sum': None,\n",
    "        'is_solved': False,\n",
    "        'ratio': None,\n",
    "        'omega': None,\n",
    "        'is_KF_solved': False,\n",
    "        'is_accepted': False,\n",
    "        'parameters': {\n",
    "            'prior': {item: None for item in model_params if item in prior_dist.keys()},\n",
    "            'prior_pdf': {item: None for item in model_params if item in prior_dist.keys()},\n",
    "            'posterior': {item: None for item in model_params if item in prior_dist.keys()}\n",
    "        },\n",
    "        'shocks': {\n",
    "            'prior': {item: None for item in shock_names},\n",
    "            'posterior': {item: None for item in shock_names}\n",
    "        }\n",
    "    }\n",
    "    # current posterior\n",
    "    old_posterior = {item: vals[-1] for item, vals in param_posterio_list.items()}\n",
    "    old_loglike = loglike_list[-1]\n",
    "    \n",
    "    draw_dict['parameters']['posterior'] = old_posterior\n",
    "    draw_dict['shocks']['posterior'] = {item: vals[-1] for item, vals in shock_posterior_list.items()}\n",
    "    \n",
    "    # sample from priors\n",
    "    prior, shocks = sample_from_priors(prior_dist, mod_params, shock_names)\n",
    "    \n",
    "    draw_dict['parameters']['prior'].update(prior)\n",
    "    draw_dict['shocks']['prior'].update(shocks)\n",
    "    \n",
    "    mod.free_param_dict.update(prior)\n",
    "    mod.shock_priors.update(shocks)\n",
    "    \n",
    "    # sovle mdoel\n",
    "    is_solved, mod = solve_updated_mod(mod, verbose=verbose) #, model_is_linear=mod_is_linear)\n",
    "    if not is_solved:\n",
    "        output_dict[i] = draw_dict\n",
    "        continue\n",
    "    else:\n",
    "        draw_dict['is_solved'] = True\n",
    "        counter_solved += 1\n",
    "            \n",
    "    # get Kalman filter initial condition\n",
    "    T, R = mod.T.values, mod.R.values\n",
    "    H, Z, T, R, QN, zs = set_up_kalman_filter(R=R, T=T, observed_data=train[observed_vars].values, observed_vars=observed_vars, \n",
    "                                              shock_names=shock_names, shocks_drawn_prior=shocks, state_variables=state_variables)\n",
    "       \n",
    "    # set up Kalman filter\n",
    "    kfilter = KalmanFilter(len(state_variables), len(observed_vars))\n",
    "    kfilter.F = T\n",
    "    kfilter.Q = QN\n",
    "    kfilter.H = Z\n",
    "    kfilter.R = H\n",
    "\n",
    "    # run Kalman filter\n",
    "    try:\n",
    "        saver = Saver(kfilter)\n",
    "        mu, cov, _, _ = kfilter.batch_filter(zs, saver=saver)\n",
    "        ll = saver.log_likelihood\n",
    "        \n",
    "         # catch -math.inf values in log_likelihood\n",
    "        if len([val for val in ll if val == -math.inf]) >0:\n",
    "            output_dict[i] = draw_dict\n",
    "            continue\n",
    "        \n",
    "        # otherwise keep going\n",
    "        new_loglike = np.sum(ll)\n",
    "        loglike_list.append(new_loglike)\n",
    "    \n",
    "        draw_dict['log_like_sum'] = new_loglike\n",
    "        draw_dict['log_like_list'] = ll\n",
    "        \n",
    "        draw_dict['is_KF_solved'] = True\n",
    "        counter_kalman += 1\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        output_dict[i] = draw_dict\n",
    "        continue\n",
    "        \n",
    "    #### MH #####  \n",
    "    # MH ratio\n",
    "    prior_pdf = get_arr_pdf_from_dist(prior, prior_dist)\n",
    "    draw_dict['parameters']['prior_pdf'] = dict(zip(prior.keys(), prior_pdf))\n",
    "    \n",
    "    ratio = ((new_loglike * prior_pdf) / (old_loglike * get_arr_pdf_from_dist(old_posterior, prior_dist))).mean()\n",
    "    ω = min([ratio, 1])\n",
    "    draw_dict['ratio'] = ratio\n",
    "    draw_dict['omega'] = ω\n",
    "    random = np.random.uniform(0, 1)\n",
    "        \n",
    "    # merge draws prior into posterior \n",
    "    if random <= ω:\n",
    "        is_accepted = True\n",
    "        counter_accp += 1.\n",
    "        draw_dict['is_accepted'] = is_accepted\n",
    "        \n",
    "        # update param posterior\n",
    "        for key in prior.keys():\n",
    "            param_posterio_list[key].append(prior[key])\n",
    "        \n",
    "        # update shock posterior\n",
    "        for key in shock_posterior_list:\n",
    "            shock_posterior_list[key].append(shocks[key])\n",
    "                \n",
    "    else:\n",
    "        # leave posterior unaltered and restart\n",
    "        is_accepted = False\n",
    "        \n",
    "    # save output    \n",
    "    output_dict[i] = draw_dict\n",
    "        \n",
    "\n",
    "# print stats\n",
    "print('\\nloop ran for', (time.time() - start) / 60, 'minutes')\n",
    "print('\\nsolver rate', counter_solved/n_runs)\n",
    "print('\\nacceptance rate', counter_accp/counter_solved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0c44c0-de00-44b0-8e2a-65e1638fed5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ed331715-6cef-4650-8762-ced15176aaf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [item for item in prior_dist if item not in shock_names]\n",
    "xarr = xr.Dataset(\n",
    "    {\n",
    "        # draw & param dimension\n",
    "        'posterior': (['draw', 'parameter'],[np.array(list(output_dict[i]['parameters']['posterior'].values())) for i in output_dict.keys()]),\n",
    "        'prior': (['draw', 'parameter'], [np.array(list(output_dict[i]['parameters']['prior'].values())) for i in output_dict.keys()]),\n",
    "        'prior_pdf': (['draw', 'parameter'], [np.array(list(output_dict[i]['parameters']['prior_pdf'].values())) for i in output_dict.keys()]),\n",
    "        \n",
    "        # draw dimension\n",
    "        'is_solved': (['draw'], [output_dict[i]['is_accepted'] for i in output_dict.keys()]),\n",
    "        'log_likelihood': (['draw'], [output_dict[i]['log_like_sum'] for i in output_dict.keys()]),\n",
    "        'mh_ration': (['draw'], [output_dict[i]['ratio'] for i in output_dict.keys()]),\n",
    "        \n",
    "        # uni dimensional\n",
    "        'n_runs_acc': (['uni_dim'], [counter_accp]),\n",
    "        'n_runs': (['uni_dim'], [n_runs]), # number of solved models  \n",
    "    },\n",
    "    coords={\n",
    "        'draw': (['draw'], list(range(0, int(n_runs)))),\n",
    "        'parameter': (['parameter'], params),\n",
    "        'uni_dim': (['uni_dim'], [0])\n",
    "    }\n",
    ")\n",
    "\n",
    "# only accepted runs\n",
    "xarr_acc = xarr.where(xarr.is_solved).dropna('draw').copy()\n",
    "xarr_acc = xarr_acc.where(xarr_acc.draw > int(xarr_acc.n_runs_acc[0][0]/2)).dropna('draw')\n",
    "\n",
    "# get quantiles of parameters\n",
    "arr_nan = deepcopy(xarr_acc.posterior.values)\n",
    "arr_nan = np.array(arr_nan, dtype=float)\n",
    "\n",
    "for i in range(0, arr_nan.shape[1]):\n",
    "    arr_no_nan = arr_nan[~np.isnan(arr_nan[:, i]), i]\n",
    "    arr_nan[~np.isnan(arr_nan[:, i]), i] = [percentileofscore(arr_no_nan, x, 'rank') for x in arr_no_nan]\n",
    "xarr_acc = xarr_acc.assign({'posterior_percentiles': (['draw', 'parameter'], arr_nan)})\n",
    "\n",
    "\n",
    "quantile_ind = []\n",
    "for i in [25, 50, 75]:\n",
    "    arr = np.abs(xarr_acc.posterior_percentiles.mean(axis=1) - i)\n",
    "    quantile_ind.append(np.where(arr==np.min(arr))[0][0])\n",
    "    \n",
    "xarr_acc = xarr_acc.assign({\n",
    "    'posterior_q1': (['parameter'], xarr.sel(draw=quantile_ind[0]).posterior.values),\n",
    "    'posterior_q2': (['parameter'], xarr.sel(draw=quantile_ind[1]).posterior.values),\n",
    "    'posterior_q3': (['parameter'], xarr.sel(draw=quantile_ind[2]).posterior.values)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1e1a98c6-b6ed-4312-9fcd-ec31c479a750",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LukasGrahl\\Documents\\GIT\\memoire1\\data\\posterior_est_out\\mod4_rbc_vanilla_20230426_2236.nc\n"
     ]
    }
   ],
   "source": [
    "# save output\n",
    "from datetime import datetime\n",
    "\n",
    "a = ''.join(str(datetime.now().date()).split('-'))\n",
    "b = ''.join((str(datetime.now().time()).split(':'))[:-1])\n",
    "timestamp = '_'.join([a, b])\n",
    "\n",
    "file_path = os.path.join(POST_EST_DIR, f'{mod_name}_{timestamp}.nc')\n",
    "file_path_acc = os.path.join(POST_EST_DIR, f'{mod_name}_accepted_{timestamp}.nc')\n",
    "print(file_path)\n",
    "if not os.path.exists(file_path):\n",
    "    xarr.to_netcdf(file_path)\n",
    "    \n",
    "if not os.path.exists(file_path_acc):\n",
    "    xarr_acc.to_netcdf(file_path_acc)\n",
    "    \n",
    "else:\n",
    "    print('File existst already')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90992be7-5d80-4f5c-9695-403e0aaa37df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
